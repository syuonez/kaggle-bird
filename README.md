# kaggle-bird

# 目的　金メダル

# solution　随時更新



テストセットに手でラベルを付けることは不正行為であり、永久的なアカウント禁止につながる可能性があります。

<img width="723" alt="スクリーンショット 2021-01-08 11 43 09" src="https://user-images.githubusercontent.com/59402913/103968163-b0595e80-51a6-11eb-89cc-53a9291bc75c.png">

私はそれを正しく理解しましたか？私が実際に持っていた最大の疑問符は、クリップ内の種の真陽性と偽陰性の記録が本当に「自動的にフラグが立てられない」ことを意味するかどうかについてでした=確かにわかりません（しかし、どれだけ良いかによってはそれほど可能性はありません使用されたアルゴリズムは）？

これは、真陽性と偽陰性を「主張」する損失関数を使用する必要があることを示唆していますが、確信が持てないクリップについてはもう少し「寛大」です（ただし、陽性よりも陰性である可能性が高いと推測される場合があります） ）？

非常に大きな課題の1つは、相関関係のある「基本的な検出アルゴリズム」ではフラグが立てられないものに対応するオーディオデータを用意することですが、これは間違いなくネガティブです。そうですか？

：気付かれない欠落しているラベルのトレーニング

:学習プロセスに損傷を与えるいくつかの重要なFNを削除します。これにより、パフォーマンスが突然向上します。

:これらの結果は、データセットが小さいほど、ラベルの欠落によるダメージが大きく、その結果、ラベルを破棄することで得られる性能の向上が大きいことを示しているように思われます

：テストセットの各テストオーディオには、23種のうち少なくとも1つが含まれている必要はないがある可能性大

:0.3秒のような非常に短い持続時間のtpセグメントがいくつかあるのを見ました、1）人がこれらをそのような精度/精度でどのようにラベル付けしたのか2）

:https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/203394



:データは実際には48000 Hzでサンプリングされました=>これが、サンプルレートが48000のオーディオファイルの読み取りが他のどのサンプルレートよりも速い理由

flacファイルを再生してオーディオサンプルの長さが1分であることがわかりました。flacファイルを読み取ると、長さ1920000の配列が取得され、tfrecordファイルからwavファイルが読み取られます。長さ2880000の配列が取得されます。したがって、flacファイルのサンプルレートは32000で、wavファイルのサンプルレートは16000ではなく48000です。

つまりwavに変換して扱った方がいい？

:評価は、種の存在（songtype_id歌の種類ではない）の予測のみに基づいていますが、一部の種で示されているように、トレーニングデータには2つの異なる歌があります。これらの場合、両方の歌型は種からの一般的な信号です。ソングタイプ1は、私たちのチームの生物学者によって決定された最も一般的な曲を示し、ソングタイプ4は、別の一般的な曲のバリエーションを示しています。

つまり、song1とsong４で分けた方がいい精度が出そう

:https://github.com/CVxTz/COLA_pytorch

:https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/198371



![image](https://user-images.githubusercontent.com/59402913/104118426-468ab180-536c-11eb-898a-ed80ae46d82d.png)




# 中期SMART（目標）

~10/31

S(具体的）

M（測定可能）

A（達成可能）

R（適切）

T（期限）

==========================================================

# kaggle日記　SMART（目標） 毎日更新する

# 1/7
S(具体的）

M（測定可能）

A（達成可能）

R（適切）

T（期限）

メル周波数スぺクトログラムとは

●wavファイル（生の音）にSTFT（短時間フーリエ変換）を施して
●メルフィルタバンクを適用した特徴量



:SEDタスクのモデル

開始時間とオフセット時間の情報を使用して予測を提供するにはどうすればよいですか？これを行うために、SEDタスクのモデルは、クリップの集約された予測を出力する代わりに、セグメントごとの予測を出力します。これは通常、オーディオタグ付けモデルに使用されます。

CNN特徴抽出器の出力には、周波数と時間に関する情報が含まれています（4次元である必要があります:(バッチサイズ、チャネル、周波数、時間））。したがって、周波数軸のみで集計すると、その特徴の時間情報を保持できます。地図。その機能マップには、どのタイムセグメントにどのサウンドイベントがあるかに関する情報が含まれています。

PANNモデルの優れている点は、生のオーディオクリップを入力として受け入れることです。上記のモデルのCNN特徴抽出器にチャンクを入れましょう。

PANNsCNN14Attでは、入力された生の波形は、torchlibrosaのユーティリティを使用して対数メルスペクトログラムに変換されます


この図は、サウンドイベントの検出に関して、弱い注釈とは何か、強い注釈とは何かを直感的に説明しています。このコンテストでは、弱い注釈（クリップレベルの注釈）しかありません。したがって、弱教師ありの方法でSEDモデルをトレーニングする必要があります。

==========================================================

# 10/28
S(具体的）

M（測定可能）

A（達成可能）

R（適切）

T（期限）

==========================================================

# 10/28
S(具体的）

M（測定可能）

A（達成可能）

R（適切）

T（期限）

==========================================================

# 10/28
S(具体的）

M（測定可能）

A（達成可能）

R（適切）

T（期限）
